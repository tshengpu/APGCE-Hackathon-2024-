{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c77719-5d5b-4545-8e26-2b8f3512d8e7",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66952f5-e226-465e-abcc-e1eb59f48e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/participant4/venv/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import loss\n",
    "from torch import optim\n",
    "from metrics import eval_metrics, get_epoch_acc\n",
    "from dataloader import DataLoader\n",
    "from cross_val import CrossVal\n",
    "from torchvision import transforms\n",
    "from eval import eval\n",
    "from config import ModelParameters\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Import available models, you can also explore other PyTorch models\n",
    "from cracknet import cracknet, CrackNet\n",
    "from unet import UNet, UNetResnet\n",
    "from segnet import SegNet, SegResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7641c43b-aa23-4cd9-be9e-982df074a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = \"cpu\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc9b1a1-ae9e-4422-8724-80f4c7d8a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the data directory and model filename\n",
    "DIR = 'data/' # Data directory\n",
    "MODEL_FILENAME = 'cracknet.pt' # Model filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfb8c8e-48da-494f-bc92-d490b109bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fault = []\n",
    "num_horizon = []\n",
    "num_seismic = []\n",
    "\n",
    "for name in os.listdir('../data/aug_fault_mask'):\n",
    "    if name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    code = name.replace(\"fault\",\"\").replace(\".npy\",\"\")\n",
    "    if os.path.isfile('../data/aug_horizon_mask/horizon{}.npy'.format(code)) and os.path.isfile('../data/aug_raw_seismic/seismic{}.png'.format(code)):\n",
    "        num_fault.append(name)\n",
    "        num_horizon.append('horizon{}.npy'.format(code))\n",
    "        num_seismic.append('seismic{}.png'.format(code))\n",
    "    \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'RAW_SEISMIC': [f\"{x}\" for x in num_seismic],\n",
    "    'RAW_FAULT': [f\"{x}\" for x in num_fault],\n",
    "    'RAW_HORIZON': [f\"{x}\" for x in num_horizon]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9010f4-bc81-4cf7-b8d9-26200bd05ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossVal(df, 3)\n",
    "dataloaders = cv\n",
    "# dataset = {}\n",
    "# dataset['train'] = LabelMe(data_folder=os.path.join(DIR,'train'), transform=data_transforms['train'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataset['val'] = LabelMe(data_folder=os.path.join(DIR,'val'), transform=data_transforms['val'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size = BATCH_SIZE,\n",
    "#                                             shuffle = True, num_workers = 8, \n",
    "#                                             drop_last = False)\n",
    "#                                             for x in ['train', 'val']}\n",
    "class_count = len(dataloaders[0]['train'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a2a6ec-bb90-470a-a0dc-c3c18015ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model for training, you can refer to the models that have been imported above\n",
    "model = cracknet(pretrained = ModelParameters.PRETRAINED, num_classes = class_count)\n",
    "\n",
    "my_optimizer = optim.Adam(model.parameters(), lr = ModelParameters.LEARNING_RATE) # Check https://pytorch.org/docs/stable/optim.html for other optimizers\n",
    "my_lr_scheduler = optim.lr_scheduler.StepLR(my_optimizer, step_size=25, gamma=0.1) # Check https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate for other schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ebbe8-74ed-4e6d-8e20-9aedbb05e3ff",
   "metadata": {},
   "source": [
    "## Start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db65b32b-c21d-46b2-9831-5fdd714b7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fault = []\n",
    "num_horizon = []\n",
    "num_seismic = []\n",
    "\n",
    "for name in os.listdir('../data/fault_mask'):\n",
    "    if name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    code = name.replace(\"fault\",\"\").replace(\".npy\",\"\")\n",
    "    if os.path.isfile('../data/horizon_mask/horizon{}.npy'.format(code)) and os.path.isfile('../data/raw_seismic/seismic{}.png'.format(code)):\n",
    "        num_fault.append(name)\n",
    "        num_horizon.append('horizon{}.npy'.format(code))\n",
    "        num_seismic.append('seismic{}.png'.format(code))\n",
    "    \n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'RAW_SEISMIC': [f\"{x}\" for x in num_seismic],\n",
    "    'RAW_FAULT': [f\"{x}\" for x in num_fault],\n",
    "    'RAW_HORIZON': [f\"{x}\" for x in num_horizon]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a168ee6-b89b-4d30-b69d-def537c036b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossVal(df, 3)\n",
    "dataloaders = cv\n",
    "# dataset = {}\n",
    "# dataset['train'] = LabelMe(data_folder=os.path.join(DIR,'train'), transform=data_transforms['train'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataset['val'] = LabelMe(data_folder=os.path.join(DIR,'val'), transform=data_transforms['val'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size = BATCH_SIZE,\n",
    "#                                             shuffle = True, num_workers = 8, \n",
    "#                                             drop_last = False)\n",
    "#                                             for x in ['train', 'val']}\n",
    "class_count = len(dataloaders[0]['train'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef98cd8-aef9-458f-9f02-e74fa7836f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"../shared/cracknet baseline focal lost.pt.pt\"\n",
    "model = torch.load(PATH, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbb2d75-9e6d-41fb-a776-0b5f6dfbad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 200\n",
    "dl = DataLoader([],[],[], (512, 512))\n",
    "img = []\n",
    "img.append(dl.input_transforms(Image.open(os.path.join(dl.RAW_SEISMIC_FOLDER, df.at[idx, \"RAW_SEISMIC\"]))))\n",
    "img = torch.stack(img, dim=0)\n",
    "mask = []\n",
    "mask.append(torch.from_numpy(cv2.resize(np.load(os.path.join(dl.FAULT_MASK_FOLDER, df.at[idx, \"RAW_FAULT\"])).astype(np.uint8), dl.IMAGE_SIZE, cv2.INTER_AREA).astype(np.int64)))\n",
    "mask = torch.stack(mask, dim=0)\n",
    "model = model.to(DEVICE)\n",
    "img = img.to(DEVICE)\n",
    "mask = mask.to(DEVICE)\n",
    "mask_pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0cb462-f30e-44b4-bec0-0e3b44261cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(257541), array(262144))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics(mask_pred, mask, class_count, ModelParameters.EVAL_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ea3ee6-d4fd-455b-a063-c259b1a01bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pred1 = mask_pred[0]\n",
    "mask_pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "181ad91c-9296-4878-a9f9-8c31b661447b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predict1 = torch.max(mask_pred1.data, 0)\n",
    "predict1_np = predict1.numpy()\n",
    "inverted_fault_mask = (255 - predict1_np * 255).astype('uint8')\n",
    "transform = transforms.Resize((512, 512))\n",
    "img = Image.open(os.path.join(dl.RAW_SEISMIC_FOLDER, df.at[idx, \"RAW_SEISMIC\"]))\n",
    "img = np.asarray(transform(img))\n",
    "# Convert binary image to a 3-channel image for overlay (BGR format)\n",
    "fault_mask_bgr = cv2.cvtColor(inverted_fault_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "overlay = cv2.addWeighted(img, 0.5, fault_mask_bgr, 0.5, 0)\n",
    "\n",
    "cv2.imwrite(\"overlay_img_fault.png\", overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a803ee1d-1db9-4238-b4f5-c221ac0344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9210055d-f73d-404b-a8be-dcd03818a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(labels, classes):\n",
    "    one_hot = torch.FloatTensor(labels.size()[0], classes, labels.size()[2], labels.size()[3]).zero_().to(labels.device)\n",
    "    target = one_hot.scatter_(1, labels.data, 1)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a556d92a-cb5f-4883-98bc-b02ddfb2f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3761, grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = make_one_hot(mask.unsqueeze(dim=1), classes=mask_pred.size()[1])\n",
    "output = F.softmax(mask_pred, dim=1)\n",
    "output_flat = output.contiguous().view(-1)\n",
    "target_flat = target.contiguous().view(-1)\n",
    "intersection = (output_flat * target_flat).sum()\n",
    "loss = 1 - ((2. * intersection + 1) /\n",
    "            (output_flat.sum() + target_flat.sum() + 1))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea7950d5-0302-475d-896d-0f00fdb6c523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7146, 0.5000, 0.5000,  ..., 0.5019, 0.3138, 0.5000],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "817eec35-c5e0-4ed7-b172-d3898d8a1dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9177, 0.0000, 0.0000,  ..., 0.8915, 0.8529, 0.0000],\n",
       "          [0.9456, 0.0000, 0.0000,  ..., 0.9932, 1.0765, 0.0000],\n",
       "          [0.8455, 0.0000, 0.9479,  ..., 0.0000, 0.8217, 1.1003],\n",
       "          ...,\n",
       "          [1.0743, 0.0000, 0.0000,  ..., 0.8481, 0.9486, 0.0000],\n",
       "          [0.8374, 0.0000, 1.0330,  ..., 0.9435, 0.9598, 0.7622],\n",
       "          [0.9051, 0.0000, 0.9410,  ..., 0.0000, 0.7825, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0231, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0242,  ..., 0.0037, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0425, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0060, 0.0000, 0.0075,  ..., 0.0414, 0.0738, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0075, 0.0000, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a76ec45c-8170-41a8-a0b4-531032f0864c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7146, 0.5000, 0.5000,  ..., 0.5019, 0.3138, 0.5000],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "421f90f0-8133-4794-b99f-6355d6365e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdda2e-f0d6-400c-b6b1-fe129a28545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
