{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c77719-5d5b-4545-8e26-2b8f3512d8e7",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66952f5-e226-465e-abcc-e1eb59f48e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 11:10:43.587650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731841843.608383  158919 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731841843.614813  158919 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-17 11:10:43.636370: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import loss\n",
    "from torch import optim\n",
    "from metrics import eval_metrics, get_epoch_acc\n",
    "from dataloader import DataLoader\n",
    "from cross_val import CrossVal\n",
    "from torchvision import transforms\n",
    "from eval import eval\n",
    "from config import ModelParameters, DatasetConfig\n",
    "\n",
    "# Import available models, you can also explore other PyTorch models\n",
    "from cracknet import cracknet\n",
    "from unet import UNet, UNetResnet\n",
    "from segnet import SegNet, SegResNet\n",
    "\n",
    "# https://blog.roboflow.com/how-to-use-segment-anything-model-sam/\n",
    "from segment_anything import sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7641c43b-aa23-4cd9-be9e-982df074a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757bf11-d774-4d60-a699-57a5e3bccdd6",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a19ce1-8fd3-4e9c-9432-04570d1b8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oneepoch(model, class_count, criterion, eval_metric, device, my_optimizer, my_lr_scheduler, dataloader):\n",
    "    model.train()\n",
    "    batch_loss = 0\n",
    "    batch_acc_numerator = 0\n",
    "    batch_acc_denominator = 0\n",
    "    epoch_lr = my_lr_scheduler.get_last_lr()[0]\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        my_optimizer.zero_grad()\n",
    "        mask_pred = model(inputs)\n",
    "        loss = criterion(mask_pred, labels)\n",
    "        loss.backward()\n",
    "        my_optimizer.step()\n",
    "        \n",
    "        # batch_loss += loss\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        batch_acc_numerator_tmp, batch_acc_denominator_tmp = eval_metrics(mask_pred, labels, class_count, eval_metric)\n",
    "        batch_acc_numerator += batch_acc_numerator_tmp\n",
    "        batch_acc_denominator += batch_acc_denominator_tmp\n",
    "    my_lr_scheduler.step()\n",
    "    epoch_loss = batch_loss / len(dataloader)\n",
    "    epoch_acc = get_epoch_acc(batch_acc_numerator, batch_acc_denominator, eval_metric)\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca771314-be0b-459d-a212-1a389063161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(model, class_count, criterion, eval_metric, EPOCHS, DEVICE, my_optimizer, my_lr_scheduler=None, dataloaders=None, logging=False, model_name='model.pt'):\n",
    "    model.to(DEVICE)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    lr = []\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_train_loss, epoch_train_acc, epoch_lr = train_oneepoch(model, class_count, criterion, eval_metric, DEVICE, my_optimizer, my_lr_scheduler, dataloaders['train'])\n",
    "        epoch_val_loss, epoch_val_acc = eval(model, class_count, criterion, eval_metric, DEVICE, dataloaders['val'])\n",
    "        # print(epoch_val_loss)\n",
    "        print(type(epoch_val_acc))\n",
    "        print(epoch_val_acc)\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if logging:\n",
    "            # train_loss.append(epoch_train_loss.detach().cpu().numpy().tolist())\n",
    "            train_loss.append(epoch_train_loss)\n",
    "            train_acc.append(epoch_train_acc)\n",
    "            # val_loss.append(epoch_val_loss.detach().cpu().numpy().tolist())\n",
    "            val_loss.append(epoch_val_loss)\n",
    "            val_acc.append(epoch_val_acc)\n",
    "            lr.append(epoch_lr)\n",
    "        torch.cuda.empty_cache() \n",
    "        \n",
    "        print(f'Epoch {epoch}/{EPOCHS - 1}: TrainLoss: {epoch_train_loss:.4f}, TrainAcc: {epoch_train_acc:.4f}, ValLoss: {epoch_val_loss:.4f}, ValAcc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    print('Best Acc: {:4f}'.format(best_val_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    torch.save(model, model_name + '.pt')\n",
    "    \n",
    "    # save training details\n",
    "    pd.DataFrame({'Epochs':range(EPOCHS), 'Learning Rate': lr, 'Training Loss': train_loss, \n",
    "                    'Training Acc': train_acc, 'Validation Loss': val_loss, \n",
    "                    'Validation Acc': val_acc}).to_csv(model_name + '.csv', index = False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d559991-d6e0-4d87-8b61-41dab8da2f17",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3465706",
   "metadata": {},
   "source": [
    "Inside the data directory, the structure should be following:\n",
    "- train\n",
    "    - images\n",
    "        - IL 991.png\n",
    "        - IL 992.png\n",
    "    - labels\n",
    "        - IL 991.npy\n",
    "        - IL 992.npy\n",
    "    - class_names.txt\n",
    "- val\n",
    "    - images\n",
    "        - IL 993.png\n",
    "    - labels\n",
    "        - IL 993.npy\n",
    "    - class_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ab64e",
   "metadata": {},
   "source": [
    "class_names.txt is to specify the label class name for the training\n",
    "\n",
    "Example content of class_names.txt:\n",
    "\n",
    "\\_background_ <br>\n",
    "fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc9b1a1-ae9e-4422-8724-80f4c7d8a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the data directory and model filename\n",
    "DIR = 'data/' # Data directory\n",
    "MODEL_FILENAME = 'cracknet.pt' # Model filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfb8c8e-48da-494f-bc92-d490b109bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fault = []\n",
    "num_horizon = []\n",
    "num_seismic = []\n",
    "indeces = [v for v in range(1000, 1441)]\n",
    "for name in os.listdir('../data/raw_fault'):\n",
    "    if name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "\n",
    "    num_fault.append(int(name.split('-')[1].split('.')[0]))\n",
    "\n",
    "for name in os.listdir('../data/raw_horizon'):\n",
    "    if name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "        \n",
    "    num_horizon.append(int(name.split('-')[1].split('.')[0]))\n",
    "\n",
    "for name in os.listdir('../data/raw_seismic'):\n",
    "    if name == '.ipynb_checkpoints':\n",
    "        continue\n",
    "        \n",
    "    num_seismic.append(int(name.split('-')[1].split('.')[0]))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'RAW_SEISMIC': [f\"seismic-{x}.png\" if x in num_seismic else None for x in indeces],\n",
    "    'RAW_FAULT': [f\"fault-{x}.npy\" if x in num_fault else None for x in indeces],\n",
    "    'RAW_HORIZON': [f\"horizon-{x}.npy\" if x in num_horizon else None for x in indeces]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9010f4-bc81-4cf7-b8d9-26200bd05ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossVal(df, 3)\n",
    "dataloaders = cv[0]\n",
    "# dataset = {}\n",
    "# dataset['train'] = LabelMe(data_folder=os.path.join(DIR,'train'), transform=data_transforms['train'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataset['val'] = LabelMe(data_folder=os.path.join(DIR,'val'), transform=data_transforms['val'],\n",
    "#                                 img_size=(1024, 1024))\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size = BATCH_SIZE,\n",
    "#                                             shuffle = True, num_workers = 8, \n",
    "#                                             drop_last = False)\n",
    "#                                             for x in ['train', 'val']}\n",
    "class_count = len(dataloaders['train'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a2a6ec-bb90-470a-a0dc-c3c18015ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model for training, you can refer to the models that have been imported above\n",
    "# model = cracknet(pretrained = ModelParameters.PRETRAINED, num_classes = class_count)\n",
    "model = UNet(num_classes = class_count)\n",
    "\n",
    "# MODEL_TYPE = \"vit_h\"\n",
    "# CHECKPOINT_PATH = \"meta_pretrained/sam_vit_h_4b8939.pth\"\n",
    "# model = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "# # sam.to(device=DEVICE)\n",
    "\n",
    "my_optimizer = optim.Adam(model.parameters(), lr = ModelParameters.LEARNING_RATE) # Check https://pytorch.org/docs/stable/optim.html for other optimizers\n",
    "my_lr_scheduler = optim.lr_scheduler.StepLR(my_optimizer, step_size=25, gamma=0.1) # Check https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate for other schedulers\n",
    "# my_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(my_optimizer,\n",
    "#                                                       factor=0.1, \n",
    "#                                                       patience=10,\n",
    "#                                                       threshold=0.000001\n",
    "#                                                       ) # Check https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate for other schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ebbe8-74ed-4e6d-8e20-9aedbb05e3ff",
   "metadata": {},
   "source": [
    "## Start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef98cd8-aef9-458f-9f02-e74fa7836f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([1, 3, 512, 512])\n",
      "########\n",
      "<class 'float'>\n",
      "0.6990347475774826\n",
      "Epoch 0/2: TrainLoss: 0.0364, TrainAcc: 0.6982, ValLoss: 0.0135, ValAcc: 0.6990\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([1, 3, 512, 512])\n",
      "########\n",
      "<class 'float'>\n",
      "0.6994303099570736\n",
      "Epoch 1/2: TrainLoss: 0.0069, TrainAcc: 0.7051, ValLoss: 0.0055, ValAcc: 0.6994\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([2, 3, 512, 512])\n",
      "########\n",
      "########\n",
      "torch.Size([1, 3, 512, 512])\n",
      "########\n",
      "<class 'float'>\n",
      "0.6994404206352849\n",
      "Epoch 2/2: TrainLoss: 0.0041, TrainAcc: 0.7051, ValLoss: 0.0035, ValAcc: 0.6994\n",
      "Best Acc: 0.699440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (start_conv): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down1): encoder(\n",
       "    (down_conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (down2): encoder(\n",
       "    (down_conv): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (down3): encoder(\n",
       "    (down_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (down4): encoder(\n",
       "    (down_conv): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (middle_conv): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up1): decoder(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (up_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2): decoder(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (up_conv): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3): decoder(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (up_conv): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up4): decoder(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (up_conv): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main(model, class_count, ModelParameters.CRITERION, ModelParameters.EVAL_METRIC,\n",
    "           # 1,                  # Epochs\n",
    "           ModelParameters.EPOCHS,\n",
    "           DEVICE, my_optimizer, \n",
    "           my_lr_scheduler, dataloaders, \n",
    "           logging = ModelParameters.LOGGING, \n",
    "           model_name = MODEL_FILENAME\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895f22c9-31cf-45c4-b5e1-df21bda7012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/participant4/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/participant4/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/participant4/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/participant4/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "cracknet_model = cracknet(pretrained = ModelParameters.PRETRAINED, num_classes = class_count)\n",
    "cracknet_model_total_params = sum(p.numel() for p in cracknet_model.parameters())\n",
    "\n",
    "unet_model = UNet(num_classes = class_count)\n",
    "unet_model_total_params = sum(p.numel() for p in unet_model.parameters())\n",
    "\n",
    "unet_resnet_model = UNetResnet(num_classes = class_count)\n",
    "unet_resnet_model_total_params = sum(p.numel() for p in unet_resnet_model.parameters())\n",
    "\n",
    "segnet_model = SegNet(num_classes = class_count)\n",
    "segnet_model_total_params  = sum(p.numel() for p in segnet_model.parameters())\n",
    "\n",
    "segresnet_model = SegResNet(num_classes = class_count)\n",
    "segresnet_model_total_params  = sum(p.numel() for p in segresnet_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af72315d-9840-40cd-a2d6-9bef818b53cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49320390"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cracknet_model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe041f0-45c4-4322-a26d-041e2d5a5ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26355234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f046dc-628b-4bcc-90ea-e27fe58c09b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29999920"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_resnet_model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5b4db4e-1081-4135-a13b-d3ed44037a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16310850"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segnet_model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58aaba51-8226-478c-95f9-001dad495d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53553346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segresnet_model_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c4feb-3818-4d87-b54a-200ef2172c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
