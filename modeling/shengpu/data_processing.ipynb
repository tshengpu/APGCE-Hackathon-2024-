{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818ef734-7790-4e4d-a515-43cfe8b5e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b75073-b948-4284-8445-96be55bf03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Gaussian kernel\n",
    "def create_gaussian_kernel(kernel_size=5, sigma=1.0):\n",
    "    x = torch.arange(-(kernel_size // 2), (kernel_size // 2) + 1, dtype=torch.float32)\n",
    "    y = x[:, None]\n",
    "    kernel = torch.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55c7fc75-fac3-4ffe-884c-7a783bafbc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom thresholding transform\n",
    "class ThresholdTransform:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        # return torch.where(tensor < self.threshold, 1, tensor)\n",
    "        tensor = torch.where(tensor < self.threshold, 1, tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de99465d-289c-443e-bb62-f8ed078317f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treshold = 0.8 ; Current Cutoff = 204\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be Tensor or ndarray. Got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 48\u001b[0m\n\u001b[1;32m     40\u001b[0m processed_tensor \u001b[38;5;241m=\u001b[39m transform(image)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# processed_tensor = processed_tensor.unsqueeze(0)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Apply thresholding\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# tensor_image = torch.where(processed_tensor < (floor(PIXEL_CUTOFF_THRESHOLD*255) / 255.0), 0, processed_tensor)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Convert back to image\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m \u001b[43mto_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# processed_image = to_pil(tensor_image)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m processed_image \n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:234\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:268\u001b[0m, in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    266\u001b[0m     pic \u001b[38;5;241m=\u001b[39m pic\u001b[38;5;241m.\u001b[39mnumpy(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pic, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be Tensor or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# if 2D image, add channel dimension (HWC)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     pic \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(pic, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be Tensor or ndarray. Got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "INPUT_PATH = \"../data/aug_raw_seismic\"\n",
    "OUTPUT_PATH = \"shengpu/sample_output\"\n",
    "\n",
    "PIXEL_CUTOFF_THRESHOLD = 0.8\n",
    "print(f\"Treshold = {PIXEL_CUTOFF_THRESHOLD} ; Current Cutoff = {floor(PIXEL_CUTOFF_THRESHOLD*255)}\")\n",
    "\n",
    "# # Gaussian kernel for convolution\n",
    "# KERNAL = 10\n",
    "# SIGMA = 0.1\n",
    "# kernel = create_gaussian_kernel(kernel_size=KERNAL, sigma=SIGMA)\n",
    "# kernel = kernel.expand(3, 1, -1, -1)  # For 3 color channels (RGB)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# image_file = f\"{INPUT_PATH}/seismic-1013.png\"\n",
    "image_file = f\"{INPUT_PATH}/seismic-1013_1209_1414_1.png\"\n",
    "output_file = f\"{OUTPUT_PATH}/a.png\"\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize to 256x256\n",
    "    transforms.ToTensor(),          # Convert to PyTorch Tensor\n",
    "    ThresholdTransform(PIXEL_CUTOFF_THRESHOLD),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    # transforms.Normalize([255/2, 255/2, 255/2], [0.229, 0.224, 0.225]),\n",
    "    # transforms.Lambda(lambda x: (x - 0.5) * 2)  # Scale to [-1, 1]\n",
    "    \n",
    "    # transforms.ToPILImage()         # Convert back to PIL Image for saving\n",
    "])\n",
    "\n",
    "# Define transformations to load and save images\n",
    "to_tensor = transforms.ToTensor()  # Convert image to tensor\n",
    "to_pil = transforms.ToPILImage()  # Convert tensor back to image\n",
    "\n",
    "# Load image\n",
    "image = Image.open(image_file).convert(\"RGB\")\n",
    "\n",
    "# Apply transformations\n",
    "processed_tensor = transform(image)\n",
    "# processed_tensor = processed_tensor.unsqueeze(0)\n",
    "\n",
    "# Apply thresholding\n",
    "# tensor_image = torch.where(processed_tensor < (floor(PIXEL_CUTOFF_THRESHOLD*255) / 255.0), 0, processed_tensor)\n",
    "\n",
    "# Convert back to image\n",
    "\n",
    "processed_image = to_pil(processed_tensor)\n",
    "# processed_image = to_pil(tensor_image)\n",
    "processed_image \n",
    "\n",
    "# Save the processed image\n",
    "# processed_image.save(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1bab496-4478-4511-92b9-8c63b0bc1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_PATH = \"../data/raw_seismic\"\n",
    "# OUTPUT_PATH = \"shengpu/sample_output\"\n",
    "\n",
    "# PIXEL_CUTOFF_THRESHOLD = 0.5\n",
    "# print(f\"Treshold = {PIXEL_CUTOFF_THRESHOLD} ; Current Cutoff = {floor(PIXEL_CUTOFF_THRESHOLD*255)}\")\n",
    "\n",
    "# # Gaussian kernel for convolution\n",
    "# KERNAL = 3\n",
    "# SIGMA = 5\n",
    "# kernel = create_gaussian_kernel(kernel_size=KERNAL, sigma=SIGMA)\n",
    "# kernel = kernel.expand(3, 1, -1, -1)  # For 3 color channels (RGB)\n",
    "\n",
    "\n",
    "# # Create output directory if it doesn't exist\n",
    "# os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# image_file = f\"{INPUT_PATH}/seismic-1013.png\"\n",
    "# output_file = f\"{OUTPUT_PATH}/a.png\"\n",
    "\n",
    "# # Define image transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((1024, 1024)),  # Resize to 256x256\n",
    "#     transforms.ToTensor(),          # Convert to PyTorch Tensor\n",
    "#     # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize\n",
    "#     # transforms.ToPILImage()         # Convert back to PIL Image for saving\n",
    "# ])\n",
    "\n",
    "# # Load image\n",
    "# image = Image.open(image_file).convert(\"RGB\")\n",
    "\n",
    "# # Apply transformations\n",
    "# processed_tensor = transform(image)\n",
    "# processed_tensor = processed_tensor.unsqueeze(0)\n",
    "\n",
    "# # Apply Gaussian blur (convolution)\n",
    "# padded_image = torch.nn.functional.pad(processed_tensor, (2, 2, 2, 2), mode='reflect')  # Padding\n",
    "# denoised_image = torch.nn.functional.conv2d(padded_image, kernel, groups=3)\n",
    "\n",
    "# # Convert back to PIL Image\n",
    "# processed_image = transforms.ToPILImage()(denoised_image.squeeze(0))\n",
    "# processed_image\n",
    "# # processed_image.save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
